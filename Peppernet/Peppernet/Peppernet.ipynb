{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sRopP0XxX3xJ",
    "outputId": "c19703c5-f1f3-4dda-c880-f258e46a615c"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0NUdSHQYX2yG",
    "outputId": "93a39caa-54fe-4fd4-9c5d-be98d1044005"
   },
   "outputs": [],
   "source": [
    "%pip install ultralytics supervision roboflow\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bvg_kwnHIlaM",
    "outputId": "288bdeb1-da05-4fad-dddf-292856e45063"
   },
   "outputs": [],
   "source": [
    "!yolo task=detect mode=predict model=yolov8n.pt conf=0.25 source='https://www.thewallstreetexperience.com/wp-content/uploads/2021/12/pexels-helena-lopes-1389339-1.jpg' save=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Set paths\n",
    "dataset_path = \"/home/kobe/Desktop/Peppernet/Data/\"\n",
    "images_dir = os.path.join(dataset_path, \"images\")\n",
    "labels_dir = os.path.join(dataset_path, \"labels\")\n",
    "classes_file = os.path.join(dataset_path, \"classes.txt\")\n",
    "output_yaml = os.path.join(dataset_path, \"data.yaml\")\n",
    "\n",
    "# Split ratios\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "# Collect all image files\n",
    "image_files = sorted(Path(images_dir).glob(\"**/*.jpg\"))  # Adjust extension if necessary\n",
    "total_files = len(image_files)\n",
    "\n",
    "# Shuffle and split\n",
    "random.seed(42)  # For reproducibility\n",
    "random.shuffle(image_files)\n",
    "train_files = image_files[:int(train_ratio * total_files)]\n",
    "val_files = image_files[int(train_ratio * total_files):int((train_ratio + val_ratio) * total_files)]\n",
    "test_files = image_files[int((train_ratio + val_ratio) * total_files):]\n",
    "\n",
    "# Create directories for split datasets\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(images_dir, split), exist_ok=True)\n",
    "    os.makedirs(os.path.join(labels_dir, split), exist_ok=True)\n",
    "\n",
    "# Move files\n",
    "def move_files(files, split):\n",
    "    for file in files:\n",
    "        image_dest = os.path.join(images_dir, split, file.name)\n",
    "        label_src = os.path.join(labels_dir, file.stem + \".txt\")\n",
    "        label_dest = os.path.join(labels_dir, split, file.stem + \".txt\")\n",
    "\n",
    "        shutil.move(file, image_dest)\n",
    "        if os.path.exists(label_src):\n",
    "            shutil.move(label_src, label_dest)\n",
    "\n",
    "move_files(train_files, \"train\")\n",
    "move_files(val_files, \"val\")\n",
    "move_files(test_files, \"test\")\n",
    "\n",
    "# Read class names from classes.txt\n",
    "if os.path.exists(classes_file):\n",
    "    with open(classes_file, \"r\") as f:\n",
    "        class_names = [line.strip() for line in f.readlines()]\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Classes file not found at {classes_file}\")\n",
    "\n",
    "# Generate data.yaml\n",
    "data_yaml_content = f\"\"\"\n",
    "train: {os.path.join(images_dir, 'train')}\n",
    "val: {os.path.join(images_dir, 'val')}\n",
    "test: {os.path.join(images_dir, 'test')}\n",
    "nc: {len(class_names)}\n",
    "names: {class_names}\n",
    "\"\"\"\n",
    "\n",
    "with open(output_yaml, \"w\") as f:\n",
    "    f.write(data_yaml_content)\n",
    "\n",
    "print(f\"Data split completed and 'data.yaml' created at {output_yaml}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XI2XjUlvee6S",
    "outputId": "f924c5fc-97c7-4190-fbb7-7bfbdc1ced5d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# Limit GPU memory usage\n",
    "torch.cuda.set_per_process_memory_fraction(1.)  # Adjust to limit memory to 90%\n",
    "\n",
    "# Load the pre-trained YOLOv8 model\n",
    "model = YOLO('/home/kobe/Desktop/Peppernet/yolov8n.pt')\n",
    "\n",
    "# Train the model\n",
    "model.share_memory()\n",
    "results = model.train(\n",
    "    data='/home/kobe/Desktop/Peppernet/Data/data.yaml',\n",
    "    epochs=3,\n",
    "    imgsz=640,\n",
    "    batch=32,\n",
    "    device='cuda',           # Use GPU if available\n",
    "    workers=2,\n",
    "    augment=True,\n",
    "    #patience=10,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "model = YOLO('/home/kobe/Desktop/JUPYTER-ML/runs/detect/train/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-8ZODZWUeiys",
    "outputId": "d6a8620a-70cf-4a2c-ee90-c6222715f7d5"
   },
   "outputs": [],
   "source": [
    "# Validate the trained model\n",
    "metrics = model.val(data='/home/kobe/Desktop/JUPYTER-ML/Military-Vehicle-Recognition-6/data.yaml')\n",
    "print(metrics)  # Displays metrics like mAP, precision, recall, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "id": "64xpYLd6ek1e",
    "outputId": "32e3c7bc-1ac1-431e-b51a-71ee78d549a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.36 ðŸš€ Python-3.12.7 torch-2.5.1+cu121 CPU (Intel Core(TM) i7-4770 3.40GHz)\n",
      "Model summary (fused): 168 layers, 3,007,793 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/home/kobe/Desktop/Peppernet/runs/detect/train4/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 15, 8400) (6.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.41...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 0.7s, saved as '/home/kobe/Desktop/Peppernet/runs/detect/train4/weights/best.onnx' (11.7 MB)\n",
      "\n",
      "Export complete (1.0s)\n",
      "Results saved to \u001b[1m/home/kobe/Desktop/Peppernet/runs/detect/train4/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/home/kobe/Desktop/Peppernet/runs/detect/train4/weights/best.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=/home/kobe/Desktop/Peppernet/runs/detect/train4/weights/best.onnx imgsz=640 data=/home/kobe/Desktop/Peppernet/Data/data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/kobe/Desktop/Peppernet/runs/detect/train4/weights/best.onnx'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the trained model\n",
    "model = YOLO('/home/kobe/Desktop/Peppernet/runs/detect/train4/weights/best.pt')\n",
    "model.export(format='onnx', opset=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 859
    },
    "id": "lgmWUbCK2-RU",
    "outputId": "b00244ec-e976-436c-fd7d-b1715bcc8893"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image as IPyImage\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import supervision as sv\n",
    "\n",
    "# Define the folder path\n",
    "folder_path = '/home/kobe/Desktop/Peppernet/TEST'\n",
    "\n",
    "# Get a list of all image files in the folder (adjust the file extension if necessary)\n",
    "image_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Select a random image file\n",
    "random_image_path = os.path.join(folder_path, random.choice(image_files))\n",
    "\n",
    "# Load the image\n",
    "image = Image.open(random_image_path)\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO('/home/kobe/Desktop/Peppernet/runs/detect/train7/weights/best.pt')\n",
    "\n",
    "# Run the YOLO model on the image\n",
    "result = model.predict(image, conf=0.375)[0]\n",
    "\n",
    "# Access detection boxes, confidence, and class labels\n",
    "result.boxes.xyxy\n",
    "result.boxes.conf\n",
    "result.boxes.cls\n",
    "\n",
    "# Convert detections to supervision format\n",
    "detections = sv.Detections.from_ultralytics(result)\n",
    "\n",
    "# Annotate boxes and labels\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator(text_color=sv.Color.BLACK)\n",
    "detections = detections.with_nms(threshold=0.5)  # Adjust threshold as needed\n",
    "# Create a copy of the image and annotate it\n",
    "annotated_image = image.copy()\n",
    "annotated_image = box_annotator.annotate(annotated_image, detections=detections)\n",
    "annotated_image = label_annotator.annotate(annotated_image, detections=detections)\n",
    "\n",
    "# Plot the annotated image\n",
    "# sv.plot_image(annotated_image, size=(10, 10))\n",
    "\n",
    "output_path = \"/home/kobe/Desktop/annotated_image.jpg\"\n",
    "annotated_image.save(output_path)\n",
    "\n",
    "# Display the saved image using IPython\n",
    "display(IPyImage(filename=output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
